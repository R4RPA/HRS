{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUuSBiGtXqq4",
        "outputId": "dc1f7b01-a85f-48c3-bc17-2e5fc782d0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: pyreadstat in /usr/local/lib/python3.10/dist-packages (1.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: pyreadstat in /usr/local/lib/python3.10/dist-packages (1.2.4)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyreadstat) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.0->pyreadstat) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas pyreadstat\n",
        "!pip install pyreadstat"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_df(result,old_column_names,new_column_names,year):\n",
        "  result=result[old_column_names]\n",
        "  result = result.rename(columns=dict(zip(old_column_names, new_column_names)))\n",
        "  result['age']=year-result['birthyear']\n",
        "  result['year_data']=int(year)\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "kE-U9G5GZdOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 2006"
      ],
      "metadata": {
        "id": "5CUG_JJENC-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pyreadstat\n",
        "\n",
        "# Replace 'your_file.sav' with the path to your .sav file\n",
        "file_path = '/content/h06f4a.sav'\n",
        "\n",
        "# Read the .sav file with encoding\n",
        "df, meta = pyreadstat.read_sav(file_path)\n",
        "df.columns = df.columns.str.upper()\n",
        "\n",
        "needed_col=[\"PN\", \"HHID\", \"KLB037A\", \"KLB037B\", \"KLB037C\", \"KLB037D\", \"KLB037E\",\n",
        "            \"KLB037F\", \"KLB037G\", \"KLB037H\", \"KLB037I\", \"KLB037J\",\n",
        "            \"KLB030A\", \"KLB030B\", \"KLB030C\", \"KLB030D\", \"KLB030E\",\n",
        "            \"KLB021A\", \"KLB021B\", \"KLB021C\", \"KLB021D\", \"KLB021E\", \"KLB021F\",\n",
        "            \"KLB021G\", \"KLB021H\", \"KD174\", \"KD184\", \"KD122\", \"KD142\", \"KD143\",\n",
        "            \"KD144\", \"KD145\", \"KD146\", \"KD101\", \"KX004_R\", \"KX067_R\", \"KX060_R\",\n",
        "            \"KB014\", \"KC001\", \"KB002\", \"KB028\", \"KB089M1M\",\"KB085\", \"KLB037A\",\n",
        "            \"KLB037B\", \"KLB037C\", \"KLB037D\", \"KLB037E\", \"KLB037F\", \"KLB037G\",\n",
        "            \"KLB037H\", \"KLB037I\", \"KLB037J\"]\n",
        "rename_col=[\"PN\", \"HHID\", \"AT1\",  \"AT2\", \"AT3\", \"AT4\", \"AT5\", \"AT6\", \"AT7\", \"CT1\",\n",
        "             \"CT3\", \"CT4\", \"discrimination1\", \"discrimination2\", \"discrimination3\",\n",
        "             \"discrimination4\", \"discrimination5\", \"vandalism\",\n",
        "             \"rubbish\", \"vacancy\", \"safety\", \"belonging\", \"trust\", \"friendliness\",\n",
        "             \"help\", \"immediate10\", \"delayed10\", \"backwardcount\", \"serial1\", \"serial2\",\n",
        "             \"serial3\", \"serial4\", \"serial5\", \"selfmemory\", \"birthmonth\", \"birthyear\",\n",
        "             \"sex\", \"education\", \"genhealth\", \"USborn\", \"hispanic\", \"race\", \"citizenship\",\n",
        "            \"trauma1\", \"trauma2\", \"trauma3\", \"trauma4\", \"trauma5\", \"trauma6\", \"trauma7\",\n",
        "            \"ctrauma1\", \"ctrauma3\", \"ctrauma4\"\n",
        "            ]\n",
        "year=2006\n",
        "\n",
        "prefix={2006:'K',\n",
        "        2008:'L',\n",
        "        2010:'M',\n",
        "        2012:'N',\n",
        "        2014:'O',\n",
        "        2016:'P'}\n",
        "\n",
        "\n",
        "new_needed_col=[i for i in needed_col if not i.endswith('D122')]\n",
        "rename_col.remove('backwardcount')\n",
        "\n",
        "new_needed_col.append(prefix[year]+'D124')\n",
        "rename_col.append('backwardcount-try1')\n",
        "new_needed_col.append(prefix[year]+'D129')\n",
        "rename_col.append('backwardcount-try2')\n",
        "\n",
        "new_df=clean_df(df,new_needed_col,rename_col,year)\n",
        "s='rand_'+str(year)+'_single_file_extract.csv'\n",
        "new_df.to_csv(s, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "BwfLGLM2fKVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pyreadstat\n",
        "\n",
        "# Replace 'your_file.sav' with the path to your .sav file\n",
        "file_path = '/content/h08f3a.sav'\n",
        "\n",
        "# Read the .sav file with encoding\n",
        "df, meta = pyreadstat.read_sav(file_path)\n",
        "df.columns = df.columns.str.upper()\n",
        "\n",
        "needed_col=[\"PN\", \"HHID\", \"LLB037A\", \"LLB037B\", \"LLB037C\", \"LLB037D\", \"LLB037E\",\n",
        "             \"LLB037F\", \"LLB037G\", \"LLB037K\", \"LLB037L\", \"LLB037M\", \"LLB037N\",\n",
        "             \"LLB030A\", \"LLB030B\", \"LLB030C\", \"LLB030D\", \"LLB030E\", \"LLB030F\",\n",
        "             \"LLB021A\", \"LLB021B\", \"LLB021C\", \"LLB021D\", \"LLB021E\", \"LLB021F\",\n",
        "             \"LLB021G\", \"LLB021H\", \"LD174\", \"LD184\", \"LD122\", \"LD142\", \"LD143\",\n",
        "             \"LD144\", \"LD145\", \"LD146\", \"LD101\", \"LX004_R\", \"LX067_R\", \"LX060_R\",\n",
        "             \"LB014\", \"LC001\", \"LB002\", \"LB028\", \"LB089M1M\",\"LB085\", \"LLB037A\",\n",
        "            \"LLB037B\", \"LLB037C\", \"LLB037D\", \"LLB037E\", \"LLB037F\", \"LLB037G\",\n",
        "            \"LLB037K\", \"LLB037L\", \"LLB037M\", \"LLB037N\"]\n",
        "rename_col=[\"PN\", \"HHID\", \"AT1\",  \"AT2\", \"AT3\", \"AT4\", \"AT5\", \"AT6\", \"AT7\", \"CT1\", \"CT2\",\n",
        "             \"CT3\", \"CT4\", \"discrimination1\", \"discrimination2\", \"discrimination3\",\n",
        "             \"discrimination4\", \"discrimination5\", \"discrimination6\", \"vandalism\",\n",
        "             \"rubbish\", \"vacancy\", \"safety\", \"belonging\", \"trust\", \"friendliness\",\n",
        "             \"help\", \"immediate10\", \"delayed10\", \"backwardcount\", \"serial1\", \"serial2\",\n",
        "             \"serial3\", \"serial4\", \"serial5\", \"selfmemory\", \"birthmonth\", \"birthyear\",\n",
        "             \"sex\", \"education\", \"genhealth\", \"USborn\", \"hispanic\", \"race\", \"citizenship\",\n",
        "             \"trauma1\", \"trauma2\", \"trauma3\", \"trauma4\", \"trauma5\", \"trauma6\", \"trauma7\",\n",
        "             \"ctrauma1\", \"ctrauma2\", \"ctrauma3\", \"ctrauma4\"\n",
        "            ]\n",
        "year=2008\n",
        "\n",
        "prefix={2006:'K',\n",
        "        2008:'L',\n",
        "        2010:'M',\n",
        "        2012:'N',\n",
        "        2014:'O',\n",
        "        2016:'P'}\n",
        "\n",
        "\n",
        "new_needed_col=[i for i in needed_col if not i.endswith('D122')]\n",
        "rename_col.remove('backwardcount')\n",
        "\n",
        "new_needed_col.append(prefix[year]+'D124')\n",
        "rename_col.append('backwardcount-try1')\n",
        "new_needed_col.append(prefix[year]+'D129')\n",
        "rename_col.append('backwardcount-try2')\n",
        "\n",
        "new_df=clean_df(df,new_needed_col,rename_col,year)\n",
        "s='rand_'+str(year)+'_single_file_extract.csv'\n",
        "new_df.to_csv(s, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "JxyVvws3NjNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 2010"
      ],
      "metadata": {
        "id": "caXwc9cgOJCE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pyreadstat\n",
        "\n",
        "# Replace 'your_file.sav' with the path to your .sav file\n",
        "file_path = '/content/hd10f6a.sav'\n",
        "\n",
        "# Read the .sav file with encoding\n",
        "df, meta = pyreadstat.read_sav(file_path)\n",
        "df.columns = df.columns.str.upper()\n",
        "\n",
        "needed_col=[\"PN\", \"HHID\", \"MLB037A\", \"MLB037B\", \"MLB037C\", \"MLB037D\", \"MLB037E\",\n",
        "             \"MLB037F\", \"MLB037G\", \"MLB037K\", \"MLB037L\", \"MLB037M\", \"MLB037N\",\n",
        "             \"MLB030A\", \"MLB030B\", \"MLB030C\", \"MLB030D\", \"MLB030E\", \"MLB030F\",\n",
        "             \"MLB021A\", \"MLB021B\", \"MLB021C\", \"MLB021D\", \"MLB021E\", \"MLB021F\",\n",
        "             \"MLB021G\", \"MLB021H\", \"MD174\", \"MD184\", \"MD122\", \"MD142\", \"MD143\",\n",
        "             \"MD144\", \"MD145\", \"MD146\", \"MD101\", \"MX004_R\", \"MX067_R\", \"MX060_R\",\n",
        "             \"MB014\", \"MC001\", \"MB002\", \"MB028\", \"MB089M1M\",\"MB085\", \"MLB037A\",\n",
        "             \"MLB037B\", \"MLB037C\", \"MLB037D\", \"MLB037E\", \"MLB037F\", \"MLB037G\",\n",
        "             \"MLB037K\", \"MLB037L\", \"MLB037M\", \"MLB037N\"]\n",
        "rename_col=[\"PN\", \"HHID\", \"AT1\",  \"AT2\", \"AT3\", \"AT4\", \"AT5\", \"AT6\", \"AT7\", \"CT1\", \"CT2\",\n",
        "             \"CT3\", \"CT4\", \"discrimination1\", \"discrimination2\", \"discrimination3\",\n",
        "             \"discrimination4\", \"discrimination5\", \"discrimination6\", \"vandalism\",\n",
        "             \"rubbish\", \"vacancy\", \"safety\", \"belonging\", \"trust\", \"friendliness\",\n",
        "             \"help\", \"immediate10\", \"delayed10\", \"backwardcount\", \"serial1\", \"serial2\",\n",
        "             \"serial3\", \"serial4\", \"serial5\", \"selfmemory\", \"birthmonth\", \"birthyear\",\n",
        "             \"sex\", \"education\", \"genhealth\", \"USborn\", \"hispanic\", \"race\", \"citizenship\",\n",
        "             \"trauma1\", \"trauma2\", \"trauma3\", \"trauma4\", \"trauma5\", \"trauma6\", \"trauma7\",\n",
        "             \"ctrauma1\", \"ctrauma2\", \"ctrauma3\", \"ctrauma4\"\n",
        "            ]\n",
        "year=2010\n",
        "\n",
        "prefix={2006:'K',\n",
        "        2008:'L',\n",
        "        2010:'M',\n",
        "        2012:'N',\n",
        "        2014:'O',\n",
        "        2016:'P'}\n",
        "\n",
        "\n",
        "new_needed_col=[i for i in needed_col if not i.endswith('D122')]\n",
        "rename_col.remove('backwardcount')\n",
        "\n",
        "new_needed_col.append(prefix[year]+'D124')\n",
        "rename_col.append('backwardcount-try1')\n",
        "new_needed_col.append(prefix[year]+'D129')\n",
        "rename_col.append('backwardcount-try2')\n",
        "\n",
        "new_df=clean_df(df,new_needed_col,rename_col,year)\n",
        "s='rand_'+str(year)+'_single_file_extract.csv'\n",
        "new_df.to_csv(s, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "qLCrA2BqOKOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 2012"
      ],
      "metadata": {
        "id": "TxBjOM1UOWap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pyreadstat\n",
        "\n",
        "# Replace 'your_file.sav' with the path to your .sav file\n",
        "file_path = '/content/h12f3a.sav'\n",
        "\n",
        "# Read the .sav file with encoding\n",
        "df, meta = pyreadstat.read_sav(file_path)\n",
        "df.columns = df.columns.str.upper()\n",
        "\n",
        "needed_col=[\"PN\", \"HHID\", \"NLB037A\", \"NLB037B\", \"NLB037C\", \"NLB037D\", \"NLB037E\",\n",
        "             \"NLB037F\", \"NLB037G\", \"NLB037K\", \"NLB037L\", \"NLB037M\", \"NLB037N\",\n",
        "             \"NLB030A\", \"NLB030B\", \"NLB030C\", \"NLB030D\", \"NLB030E\", \"NLB030F\",\n",
        "             \"NLB021A\", \"NLB021B\", \"NLB021C\", \"NLB021D\", \"NLB021E\", \"NLB021F\",\n",
        "             \"NLB021G\", \"NLB021H\", \"ND174\", \"ND184\", \"ND122\", \"ND142\", \"ND143\",\n",
        "             \"ND144\", \"ND145\", \"ND146\", \"ND101\", \"NX004_R\", \"NX067_R\", \"NX060_R\",\n",
        "             \"NB014\", \"NC001\", \"NB002\", \"NB028\", \"NB089M1M\",\"NB085\", \"NLB037A\",\n",
        "             \"NLB037B\", \"NLB037C\", \"NLB037D\", \"NLB037E\", \"NLB037F\", \"NLB037G\",\n",
        "             \"NLB037K\", \"NLB037L\", \"NLB037M\", \"NLB037N\"]\n",
        "rename_col=[\"PN\", \"HHID\", \"AT1\",  \"AT2\", \"AT3\", \"AT4\", \"AT5\", \"AT6\", \"AT7\", \"CT1\", \"CT2\",\n",
        "             \"CT3\", \"CT4\", \"discrimination1\", \"discrimination2\", \"discrimination3\",\n",
        "             \"discrimination4\", \"discrimination5\", \"discrimination6\", \"vandalism\",\n",
        "             \"rubbish\", \"vacancy\", \"safety\", \"belonging\", \"trust\", \"friendliness\",\n",
        "             \"help\", \"immediate10\", \"delayed10\", \"backwardcount\", \"serial1\", \"serial2\",\n",
        "             \"serial3\", \"serial4\", \"serial5\", \"selfmemory\", \"birthmonth\", \"birthyear\",\n",
        "             \"sex\", \"education\", \"genhealth\", \"USborn\", \"hispanic\", \"race\", \"citizenship\",\n",
        "             \"trauma1\", \"trauma2\", \"trauma3\", \"trauma4\", \"trauma5\", \"trauma6\", \"trauma7\",\n",
        "             \"ctrauma1\", \"ctrauma2\", \"ctrauma3\", \"ctrauma4\"\n",
        "            ]\n",
        "year=2012\n",
        "\n",
        "prefix={2006:'K',\n",
        "        2008:'L',\n",
        "        2010:'M',\n",
        "        2012:'N',\n",
        "        2014:'O',\n",
        "        2016:'P'}\n",
        "\n",
        "\n",
        "new_needed_col=[i for i in needed_col if not i.endswith('D122')]\n",
        "rename_col.remove('backwardcount')\n",
        "\n",
        "new_needed_col.append(prefix[year]+'D124')\n",
        "rename_col.append('backwardcount-try1')\n",
        "new_needed_col.append(prefix[year]+'D129')\n",
        "rename_col.append('backwardcount-try2')\n",
        "\n",
        "new_df=clean_df(df,new_needed_col,rename_col,year)\n",
        "s='rand_'+str(year)+'_single_file_extract.csv'\n",
        "new_df.to_csv(s, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "izO3NCkROX-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 2014"
      ],
      "metadata": {
        "id": "dLjbk9BSOrm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import pyreadstat\n",
        "\n",
        "# Replace 'your_file.sav' with the path to your .sav file\n",
        "file_path = '/content/h14f2b.sav'\n",
        "\n",
        "# Read the .sav file with encoding\n",
        "df, meta = pyreadstat.read_sav(file_path)\n",
        "df.columns = df.columns.str.upper()\n",
        "\n",
        "\n",
        "needed_col=[\"PN\", \"HHID\", \"OLB029A\", \"OLB029B\", \"OLB029C\", \"OLB029D\",\n",
        "             \"OLB029E\", \"OLB029F\", \"OLB020A\", \"OLB020B\", \"OLB020C\", \"OLB020D\",\n",
        "             \"OLB020E\", \"OLB020F\", \"OLB020G\", \"OLB020H\", \"OD174\", \"OD184\", \"OD122\",\n",
        "             \"OD142\", \"OD143\", \"OD144\", \"OD145\", \"OD146\", \"OD101\", \"OX004_R\",\n",
        "             \"OX067_R\", \"OX060_R\", \"OB014\", \"OC001\", \"OB002\", \"OB028\", \"OB089M1M\",\n",
        "             \"OB085\"]\n",
        "rename_col=[\"PN\", \"HHID\", \"discrimination1\", \"discrimination2\", \"discrimination3\",\n",
        "             \"discrimination4\", \"discrimination5\", \"discrimination6\", \"vandalism\",\n",
        "             \"rubbish\", \"vacancy\", \"safety\", \"belonging\", \"trust\", \"friendliness\",\n",
        "             \"help\", \"immediate10\", \"delayed10\", \"backwardcount\", \"serial1\", \"serial2\",\n",
        "             \"serial3\", \"serial4\", \"serial5\", \"selfmemory\", \"birthmonth\", \"birthyear\",\n",
        "             \"sex\", \"education\", \"genhealth\", \"USborn\", \"hispanic\", \"race\", \"citizenship\"\n",
        "            ]\n",
        "year=2014\n",
        "\n",
        "prefix={2006:'K',\n",
        "        2008:'L',\n",
        "        2010:'M',\n",
        "        2012:'N',\n",
        "        2014:'O',\n",
        "        2016:'P'}\n",
        "\n",
        "\n",
        "new_needed_col=[i for i in needed_col if not i.endswith('D122')]\n",
        "rename_col.remove('backwardcount')\n",
        "\n",
        "new_needed_col.append(prefix[year]+'D124')\n",
        "rename_col.append('backwardcount-try1')\n",
        "new_needed_col.append(prefix[year]+'D129')\n",
        "rename_col.append('backwardcount-try2')\n",
        "\n",
        "new_df=clean_df(df,new_needed_col,rename_col,year)\n",
        "s='rand_'+str(year)+'_single_file_extract.csv'\n",
        "new_df.to_csv(s, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "s2vRc3P1OswU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For 2016"
      ],
      "metadata": {
        "id": "zXoOihDpPD-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pyreadstat\n",
        "\n",
        "# Replace 'your_file.sav' with the path to your .sav file\n",
        "file_path = '/content/h16f2c.sav'\n",
        "\n",
        "# Read the .sav file with encoding\n",
        "df, meta = pyreadstat.read_sav(file_path)\n",
        "df.columns = df.columns.str.upper()\n",
        "\n",
        "\n",
        "needed_col=[\"PN\", \"HHID\", \"PLB029A\", \"PLB029B\", \"PLB029C\", \"PLB029D\",\n",
        "             \"PLB029E\", \"PLB029F\", \"PLB020A\", \"PLB020B\", \"PLB020C\", \"PLB020D\",\n",
        "             \"PLB020E\", \"PLB020F\", \"PLB020G\", \"PLB020H\", \"PD174\", \"PD184\", \"PD122\",\n",
        "             \"PD142\", \"PD143\", \"PD144\", \"PD145\", \"PD146\", \"PD101\", \"PX004_R\",\n",
        "             \"PX067_R\", \"PX060_R\", \"PB014\", \"PC001\", \"PB002\", \"PB028\", \"PB089M1M\",\n",
        "             \"PB085\"]\n",
        "rename_col=[\"PN\", \"HHID\", \"discrimination1\", \"discrimination2\", \"discrimination3\",\n",
        "             \"discrimination4\", \"discrimination5\", \"discrimination6\", \"vandalism\",\n",
        "             \"rubbish\", \"vacancy\", \"safety\", \"belonging\", \"trust\", \"friendliness\",\n",
        "             \"help\", \"immediate10\", \"delayed10\", \"backwardcount\", \"serial1\", \"serial2\",\n",
        "             \"serial3\", \"serial4\", \"serial5\", \"selfmemory\", \"birthmonth\", \"birthyear\",\n",
        "             \"sex\", \"education\", \"genhealth\", \"USborn\", \"hispanic\", \"race\", \"citizenship\"\n",
        "            ]\n",
        "year=2016\n",
        "\n",
        "prefix={2006:'K',\n",
        "        2008:'L',\n",
        "        2010:'M',\n",
        "        2012:'N',\n",
        "        2014:'O',\n",
        "        2016:'P'}\n",
        "\n",
        "\n",
        "new_needed_col=[i for i in needed_col if not i.endswith('D122')]\n",
        "rename_col.remove('backwardcount')\n",
        "\n",
        "new_needed_col.append(prefix[year]+'D124')\n",
        "rename_col.append('backwardcount-try1')\n",
        "new_needed_col.append(prefix[year]+'D129')\n",
        "rename_col.append('backwardcount-try2')\n",
        "\n",
        "new_df=clean_df(df,new_needed_col,rename_col,year)\n",
        "s='rand_'+str(year)+'_single_file_extract.csv'\n",
        "new_df.to_csv(s, index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "8lyTCIQvPFJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "clean_2006=pd.read_csv(\"/content/rand_2006_single_file_extract.csv\")\n",
        "clean_2008=pd.read_csv(\"/content/rand_2008_single_file_extract.csv\")\n",
        "clean_2010=pd.read_csv(\"/content/rand_2010_single_file_extract.csv\")\n",
        "clean_2012=pd.read_csv(\"/content/rand_2012_single_file_extract.csv\")\n",
        "clean_2014=pd.read_csv(\"/content/rand_2014_single_file_extract.csv\")\n",
        "clean_2016=pd.read_csv(\"/content/rand_2016_single_file_extract.csv\")\n"
      ],
      "metadata": {
        "id": "VaMDsb7zfXce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YYZB2YK-OIeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(clean_2006)+len(clean_2008)+len(clean_2010)+len(clean_2012)+len(clean_2014)+len(clean_2016)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g95oZ-mxzTe",
        "outputId": "d850af92-183c-402a-8e0d-5f6ef1a5d053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117933"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp=pd.concat([clean_2006, clean_2008,clean_2010,clean_2012,clean_2014,clean_2016], axis=0, ignore_index=True)"
      ],
      "metadata": {
        "id": "6xv9nEIgx6eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.to_csv(\"Merged_data_regenerate.csv\",index=False)"
      ],
      "metadata": {
        "id": "AlSJN7TVx9p5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ab9B8Y5SyAFo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}